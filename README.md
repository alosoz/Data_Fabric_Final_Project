# Data_Fabric_Final_Project

🎬 Senaryo: “HappyBooking – Veri Mühendisliği Görevi”

HappyBooking, farklı kaynaklardan gelen rezervasyon verilerini düzenleyip yönetime raporlamak isteyen bir turizm şirketi.
Şirketin hedefi: ham veriyi toplayıp işlemek, raporlamak ve canlı rezervasyon trendlerini takip etmek.

Amaç:

Farklı kaynaklardan gelen veriyi (dosya, API, stream) toplamak

Bu verileri temizleyip düzenlemek

Analiz için hazır hale getirmek

Yönetim için rapor oluşturmak

Şirket sizden bir data pipeline kurmanızı istiyor.

🧩 Kullanabileceğiniz bazı araçlar:

Zorunlu: Fabric Eventstream / Lakehouse katmanları

Zorunlu: GitHub Actions (CI/CD)

Zorunlu: Docker (stream simulator için)

İsteğe bağlı: DBT (Gold dönüşümleri için)

İsteğe bağlı: Great Expectations (data quality için)

📌 Görev

Veri toplama: Ham veriyi şirket sistemine alın. (dosya + stream)

Veri işleme: Verileri temizleyin, düzenleyin.

Raporlama: Yönetimin ihtiyacını karşılayacak dashboard oluşturun.

(İsteğe bağlı) Verinizin kalitesini test edin veya dönüşümleri DBT ile yönetin.

👉 Sizden beklenen:

Hangi araçları nerede kullanacağınızı belirlemek

Bir veri akışı (pipeline) tasarlamak

Çözümünüzü kısaca açıklamak
