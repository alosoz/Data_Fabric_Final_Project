# Data_Fabric_Final_Project

ğŸ¬ Senaryo: â€œHappyBooking â€“ Veri MÃ¼hendisliÄŸi GÃ¶reviâ€

HappyBooking, farklÄ± kaynaklardan gelen rezervasyon verilerini dÃ¼zenleyip yÃ¶netime raporlamak isteyen bir turizm ÅŸirketi.
Åirketin hedefi: ham veriyi toplayÄ±p iÅŸlemek, raporlamak ve canlÄ± rezervasyon trendlerini takip etmek.

AmaÃ§:

FarklÄ± kaynaklardan gelen veriyi (dosya, API, stream) toplamak

Bu verileri temizleyip dÃ¼zenlemek

Analiz iÃ§in hazÄ±r hale getirmek

YÃ¶netim iÃ§in rapor oluÅŸturmak

Åirket sizden bir data pipeline kurmanÄ±zÄ± istiyor.

ğŸ§© KullanabileceÄŸiniz bazÄ± araÃ§lar:

Zorunlu: Fabric Eventstream / Lakehouse katmanlarÄ±

Zorunlu: GitHub Actions (CI/CD)

Zorunlu: Docker (stream simulator iÃ§in)

Ä°steÄŸe baÄŸlÄ±: DBT (Gold dÃ¶nÃ¼ÅŸÃ¼mleri iÃ§in)

Ä°steÄŸe baÄŸlÄ±: Great Expectations (data quality iÃ§in)

ğŸ“Œ GÃ¶rev

Veri toplama: Ham veriyi ÅŸirket sistemine alÄ±n. (dosya + stream)

Veri iÅŸleme: Verileri temizleyin, dÃ¼zenleyin.

Raporlama: YÃ¶netimin ihtiyacÄ±nÄ± karÅŸÄ±layacak dashboard oluÅŸturun.

(Ä°steÄŸe baÄŸlÄ±) Verinizin kalitesini test edin veya dÃ¶nÃ¼ÅŸÃ¼mleri DBT ile yÃ¶netin.

ğŸ‘‰ Sizden beklenen:

Hangi araÃ§larÄ± nerede kullanacaÄŸÄ±nÄ±zÄ± belirlemek

Bir veri akÄ±ÅŸÄ± (pipeline) tasarlamak

Ã‡Ã¶zÃ¼mÃ¼nÃ¼zÃ¼ kÄ±saca aÃ§Ä±klamak
